D'accord ! Je vais rechercher des outils spécifiques pour le diagnostic et l’optimisation des performances réseau sous Linux, ainsi que des instructions détaillées pour tester ces performances. De plus, j'inclurai une introduction à la supervision centralisée avec Prometheus.

Je vous tiens informé dès que j'ai terminé la recherche.

# Guide de maintenance de la configuration réseau sous Linux (optimisation des performances)

## Outils de diagnostic et d’optimisation des performances réseau

Plusieurs outils Linux permettent de **mesurer, surveiller et diagnostiquer** les performances réseau. Voici une liste de quelques outils indispensables :

- **Ping et traceroute** : Outils de base pour tester la connectivité et la latence. La commande `ping` envoie des paquets ICMP à une destination et mesure le temps aller-retour, tandis que `traceroute` (ou son équivalent amélioré `mtr`) affiche le chemin réseau et la latence à chaque saut ([Comment identifier un goulot d’étranglement LAN avec 5 outils et techniques](https://fr.linkedin.com/advice/3/how-can-you-identify-lan-bottleneck-skills-computer-networking-ushzf?lang=fr#:~:text=Ping%20et%20traceroute%20sont%20des,r%C3%A9ponse%20%C3%A9lev%C3%A9%20ou%20un%20d%C3%A9lai)). Ils aident à repérer des liens lents ou des nœuds intermédiaires posant problème (par ex. un routeur en panne ou une latence anormale).  
- **iftop** (*Interface Top*) : Outil en temps réel qui surveille le trafic sur une interface réseau. Il affiche en continu les connexions actives avec le débit utilisé par chacune, en entrée et en sortie ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,taux%20de%20transfert%20de%20donn%C3%A9es)). Cela fournit une vue instantanée des hôtes ou services consommant le plus de bande passante, ce qui aide à identifier d’éventuels **goulots d’étranglement** du réseau ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=,les%20goulots%20d%E2%80%99%C3%A9tranglement%20du%20r%C3%A9seau)).  
- **iperf/iperf3** : Outil de référence pour mesurer le débit maximal entre deux hôtes. En mode client/serveur, `iperf` envoie des flux de données TCP (par défaut) ou UDP pour évaluer la bande passante disponible et la qualité de la connexion (pertes, gigue) ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,du%20r%C3%A9seau%20entre%20ces%20points)) ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,de%20TCP%20pour%20le%20test)). C’est idéal pour tester la **performance brute** du réseau entre deux machines (LAN ou WAN) et valider les optimisations.  
- **netstat** (ou son successeur `ss`) : Commande fournissant des **statistiques réseau** et la liste des connexions. `netstat` affiche les connexions actives (sockets TCP/UDP), les tables de routage, les statistiques par interface, etc. ([trafic [Wiki ubuntu-fr]](http://doc.ubuntu-fr.org/trafic#:~:text=netstat%20affiche%20les%20connexions%20r%C3%A9seau%2C,tools)). Cela permet de voir le nombre de connexions établies, les ports en écoute, et d’éventuelles erreurs ou collisions au niveau des interfaces. (NB : `netstat` fait partie de l’ancien paquet `net-tools` et peut nécessiter une installation préalable sur certaines distributions ([trafic [Wiki ubuntu-fr]](http://doc.ubuntu-fr.org/trafic#:~:text=netstat%20est%20un%20programme%20issu,netstat%20est%20remplac%C3%A9%20par%20ss)). La commande moderne `ss` offre des fonctionnalités similaires, plus rapidement ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=ss%20)).)  
- **nload** : Outil en console affichant graphiquement l’utilisation de la bande passante entrante et sortante sur une interface. Il permet de visualiser les pics de trafic en temps réel et sur la durée, facilitant l’identification des moments de saturation ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=du%20r%C3%A9seau)).  
- **mtr (My Traceroute)** : Combine les fonctions de `ping` et `traceroute` en un seul outil continu. `mtr` fournit en temps réel la liste des routeurs traversés vers une destination ainsi que les latences et pertes constatées à chaque saut ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=mtr%20)). C’est très utile pour diagnostiquer où sur le trajet réseau se situent la latence ou la perte de paquets.  

*Remarque :* D’autres outils peuvent compléter cette liste (par ex. `tcpdump`/Wireshark pour analyser finement les paquets, `ethtool` pour vérifier la configuration des cartes réseau, `nethogs` pour voir la bande passante par processus, etc.), mais les outils ci-dessus couvrent les principaux besoins de diagnostic de performance.

## Tester les performances réseau avec les outils

Cette section propose des instructions détaillées pour **mesurer les performances réseau** à l’aide des outils précédents. Suivez ces méthodes pour identifier d’éventuelles limites dans votre infrastructure :

1. **Vérifier la latence et la connectivité** – *Ping* est le plus simple pour mesurer la latence entre deux machines. Par exemple : `ping -c 4 192.168.1.1` envoie 4 paquets vers l’IP cible et affiche le délai moyen en millisecondes. Une latence stable et faible indique une connexion saine; des temps de réponse très élevés ou des pertes de paquets suggèrent un problème. Si la latence est variable ou élevée, utilisez `traceroute 192.168.1.1` (ou `mtr 192.168.1.1`) pour voir où le délai augmente sur le chemin ([Comment identifier un goulot d’étranglement LAN avec 5 outils et techniques](https://fr.linkedin.com/advice/3/how-can-you-identify-lan-bottleneck-skills-computer-networking-ushzf?lang=fr#:~:text=Ping%20et%20traceroute%20sont%20des,r%C3%A9ponse%20%C3%A9lev%C3%A9%20ou%20un%20d%C3%A9lai)). Par exemple, un saut présentant un temps très élevé ou des “***” dans traceroute pourrait indiquer un routeur saturé ou filtrant le trafic.

2. **Mesurer le débit maximal (bande passante)** – Utilisez *iperf* en mode client/serveur pour tester le débit entre deux hôtes. Sur la machine serveur, lancez `iperf -s` (en écoute sur le port par défaut 5201 ou 5001 selon la version). Sur la machine cliente, exécutez `iperf -c <IP_du_serveur>` pour initier un test TCP de 10 secondes. Les résultats indiqueront le volume de données transféré et le débit en Mbits/s ou Gbits/s atteint pendant le test ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=iperf%20)) ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,12%20port%205001)). Par exemple, un résultat *Bandwidth: 95 Mbits/sec* sur un lien gigabit indiquerait un goulot d’étranglement (on s’attend plutôt à ~940 Mbits/s sur un réseau 1 Gbps). Pour tester en UDP et mesurer la perte de paquets ou la gigue, ajoutez `-u` côté client (`iperf -c <IP> -u -b 100M` pour tester à 100 Mb/s en UDP). **Astuce :** Vous pouvez ajuster la durée du test avec `-t <secondes>` et lancer plusieurs flux parallèles avec `-P <nbr_flux>` pour solliciter davantage le réseau (par exemple, `iperf -c <IP> -P 4` pour 4 flux simultanés).

3. **Surveiller le trafic en temps réel** – Pour observer l’utilisation du réseau à l’instant *t*, lancez *iftop*. Exécutez par exemple `sudo iftop -i eth0` pour surveiller l’interface `eth0` ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,adresses%20dans%20le%20r%C3%A9seau%20sp%C3%A9cifi%C3%A9)). L’écran iftop se met à jour en continu en affichant les adresses source/destination des flux actifs, avec le débit instantané, à 10 secondes et à 40 secondes. Repérez les connexions occupant le plus de bande passante (tout en bas, iftop affiche aussi le total cumulé TX/RX). Vous pouvez appuyer sur `P` dans iftop pour voir les ports, sur `n` pour désactiver la résolution DNS afin d’afficher les IP brutes ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,o%202t)). Si vous constatez que l’interface est proche de sa capacité maximale (par ex. ~100 Mbps sur Fast Ethernet, ~1 Gbps sur Gigabit), c’est un signe de saturation. De même, iftop permet d’identifier *quelle machine ou service consomme le plus* de bande passante en temps réel, ce qui oriente vers la cause du ralentissement ([Commandes Réseau Linux Essentielles à Connaître | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/reseaux/#:~:text=,quantit%C3%A9%20disproportionn%C3%A9e%20de%20ressources%20r%C3%A9seau)).

4. **Examiner les connexions et statistiques système** – Avec *netstat* ou *ss*, vous pouvez lister les connexions ouvertes et les compteurs réseau. Par exemple, `netstat -tunap` affiche toutes les connexions TCP/UDP et les ports en écoute avec les PID associés (utile pour voir si un service ouvre trop de connexions). La commande `netstat -i` donne des statistiques par interface (paquets envoyés/reçus, erreurs, collisions). Sur un système moderne, `ss -s` fournit un résumé des sockets (ex. nombre de sockets TCP établis, en écoute, etc.), et `ss -t state established` listera toutes les connexions TCP établies. Ces informations aident à voir si le serveur gère un nombre anormalement élevé de connexions simultanées ou subit des erreurs réseau (collisions Ethernet, paquets erronés) qui dégradent les performances.

5. **Utiliser nload pour une vue instantanée** – En parallèle, l’outil `nload` peut être lancé dans un terminal (`nload eth0`). Il affichera des graphiques mis à jour en temps réel du débit entrant et sortant sur l’interface, ainsi que des moyennes sur la session. Cela permet de **visualiser les pics de trafic** facilement : par exemple, on peut voir si la sortie atteint régulièrement 100 Mbps (limite d’un lien Fast Ethernet) ou si le trafic est en dents de scie, signe de rafales de données ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=du%20r%C3%A9seau)). Nload affiche aussi le volume total transféré, pratique pour évaluer la charge réseau sur une période donnée.

6. **Autres tests ciblés** – Selon les résultats obtenus, vous pouvez affiner le diagnostic. Si vous suspectez un problème de résolution de nom (DNS), testez la latence DNS (`dig` ou `nslookup`) séparément. Si un certain protocole est lent (par ex. HTTP), vous pouvez utiliser des outils spécifiques (comme `ab` ou `wrk` pour du HTTP benchmarking) pour voir si la latence provient de l’application ou du réseau. Pour des problèmes intermittents, envisagez d’enregistrer le trafic avec `tcpdump` sur une période afin d’analyser plus tard où se situent les ralentissements (par ex. retransmissions TCP visibles dans Wireshark).

En combinant ces tests, vous obtiendrez un aperçu complet des performances réseau du système, tant en termes de **latence** (ping/traceroute), de **débit** maximal (iperf), que d’**utilisation en temps réel** (iftop/nload) et de **charge de connexions** (netstat/ss). La clé est de repérer les écarts par rapport à la normale : un débit mesuré bien en dessous de la capacité théorique, une latence inhabituellement élevée, ou un taux d’erreur important sur une interface sont autant de **signaux d’alarme** à investiguer.

## Méthodologie pour identifier les goulots d’étranglement et améliorer les performances

Lorsque les tests indiquent une performance insatisfaisante, il faut **déterminer où se situe le goulot d’étranglement**. Une démarche méthodique aide à isoler la cause du problème et à apporter les bonnes solutions :

- **Collecter des indicateurs clés** : Surveillez et analysez en parallèle plusieurs paramètres : *les sources et destinations majeures de trafic, l’utilisation de la bande passante, la latence, ainsi que les taux d’erreur ou de perte* sur les interfaces ([Comment identifier un goulot d’étranglement LAN avec 5 outils et techniques](https://fr.linkedin.com/advice/3/how-can-you-identify-lan-bottleneck-skills-computer-networking-ushzf?lang=fr#:~:text=Un%20goulot%20d%E2%80%99%C3%A9tranglement%20LAN%20est,pour%20identifier%20un%20goulot%20d%E2%80%99%C3%A9tranglement)). Par exemple, une interface saturée à 100% de son débit ou affichant de nombreuses erreurs (voir `ifconfig`/`ip -s link` pour les compteurs d’erreurs) signale un problème au niveau de cette liaison.

- **Distinguer réseau vs système** : Vérifiez si le **goulot est réseau ou plutôt système**. Utilisez `top`/`htop` ou `sar` pour voir la charge CPU et RAM lors des transferts. Un CPU à 100% pendant un test de bande passante indique que la limitation peut venir du CPU (chiffrement VPN, calculs applicatifs, interruptions réseau trop nombreuses). Dans ce cas, optimiser la pile réseau du kernel ou ajouter des ressources CPU peut améliorer le débit. À l’inverse, si le CPU est peu utilisé mais que le débit plafonne en dessous des capacités attendues du lien, c’est probablement la **liaison réseau** elle-même qui limite (débit du lien insuffisant, ou latence/paquets perdus bridant le flux TCP).

- **Localiser le segment réseau limitant** : Si le problème est réseau, **déterminez où**. Est-ce sur la boucle locale du serveur (ex. une carte réseau configurée en 100 Mb/s au lieu de 1 Gb/s) ? Ou bien sur le LAN (un commutateur saturé) ? Ou encore sur la liaison Internet (FAI) ? Utilisez `traceroute/mtr` pour repérer un saut avec une latence ou une perte élevée. Consultez `ethtool eth0` pour vérifier la vitesse et le duplex de l’interface (par ex. *Speed: 1000Mb/s, Duplex: Full* signifie Gigabit full duplex – si au lieu de ça vous voyez 100Mb/s ou des erreurs de négociation, le câble ou le port peuvent brider le débit). En identifiant le segment fautif – par exemple une liaison Wi-Fi instable ou un VPN lent – on pourra concentrer les efforts dessus.

- **Analyser le trafic applicatif** : Identifiez si un **service ou protocole spécifique** cause le goulot. iftop et netstat peuvent montrer qu’une IP ou un port monopolise la bande passante. Si, par exemple, la sauvegarde nocturne sature le lien, c’est un goulot d’étranglement connu. De même, de nombreuses connexions en attente sur un port web (vues via `ss`) peuvent indiquer que le serveur web est saturé ou subit une attaque, impactant les performances réseau pour les autres. En comprenant quel trafic est en cause (streams vidéo, transferts de fichiers massifs, etc.), on peut agir plus finement (qualité de service, limitations, réordonnancement des tâches, etc.).

- **Apporter des solutions appropriées** : Une fois le ou les goulots identifiés, appliquez des **stratégies de remédiation**. Voici quelques exemples de solutions courantes :
  - *Optimisation de la configuration réseau* – Ajustez les paramètres réseau du système. Par exemple, peaufinez la table de routage si un chemin n’est pas optimal, vérifiez qu’aucune règle de pare-feu excessive ne ralentit le trafic, et configurez éventuellement du QoS (Quality of Service) pour prioriser certains flux critiques ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=,r%C3%A9seau%20en%20stockant%20localement%20des)).  
  - *Augmentation de la bande passante* – Si le lien réseau est constamment saturé (par ex. trafic entrant proche de 100% en permanence), envisagez d’augmenter la capacité : passer d’un port 1 Gb/s à 10 Gb/s, ou souscrire à une offre Internet supérieure si c’est la connexion WAN le problème ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=param%C3%A8tres%20de%20QoS%20,mettre%20%C3%A0%20niveau%20le%20mat%C3%A9riel)).  
  - *Mise en cache et compression* – Réduisez la quantité de données traversant le réseau. Par exemple, déployer un cache HTTP (Squid, CDN) pour les ressources statiques, activer la compression des données applicatives (compression HTTP, backups compressés), ou encore utiliser un proxy local pour éviter des requêtes externes redondantes. Cela allège la charge réseau perçue par les utilisateurs.  
  - *Mise à jour du matériel* – Parfois, le bottleneck vient d’un matériel obsolète ou défaillant. Remplacez une carte réseau ancienne par un modèle plus performant, assurez-vous que les câbles Ethernet sont de bonne qualité (un câble défectueux peut provoquer des retransmissions et réduire le débit). De même, un routeur ou switch gigabit bas de gamme peut avoir du mal au-delà d’un certain nombre de paquets par seconde. Investir dans du matériel plus robuste (switch administrable, routeur performant) peut lever le goulot ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=%C3%A9lev%C3%A9%2C%20il%20peut%20%C3%AAtre%20n%C3%A9cessaire,peut%20am%C3%A9liorer%20les%20performances)).  
  - *Segmentation du réseau* – Si le trafic est très élevé sur un seul réseau, envisagez de segmenter en VLAN ou sous-réseaux distincts. Par exemple, séparer le trafic de sauvegarde du trafic utilisateur sur deux VLAN différents évitera qu’ils ne se nuisent mutuellement. La réduction de la congestion par segmentation améliore les performances globales en répartissant la charge ([Optimisation des Performances d'un Serveur Linux | DevSecOps](https://blog.stephane-robert.info/docs/admin-serveurs/linux/performances/#:~:text=%C3%A9lev%C3%A9%2C%20il%20peut%20%C3%AAtre%20n%C3%A9cessaire,peut%20am%C3%A9liorer%20les%20performances)).  
  - *Tuning du kernel* – Pour des besoins pointus, Linux offre de nombreux paramètres sysctl pour le réseau (tailles de buffers TCP, files d’attente, etc.). Par exemple, augmenter `tcp_rmem`/`tcp_wmem` (tailles de fenêtres TCP) peut aider sur des liaisons à haute latence (WAN) à mieux utiliser la bande passante. Il faut toutefois les ajuster prudemment et mesurer l’impact.

En appliquant cette méthodologie (mesures, identification, action), vous pourrez **éliminer progressivement les goulots d’étranglement** et améliorer notablement les performances réseau de votre système Linux. N’oubliez pas de ne changer qu’un paramètre à la fois et de mesurer à nouveau pour bien attribuer l’effet de chaque modification.

## Supervision centralisée avec Prometheus pour le monitoring réseau

Prometheus est une solution open-source de supervision et d’alerte, conçue pour collecter des métriques temporelles et très utilisée dans l’écosystème DevOps. C’est l’un des outils de monitoring les plus **puissants et polyvalents** pour l’analyse de données en temps réel, et il est devenu un standard de fait dans la communauté ([Prometheus : Tout sur cette solution open source de monitoring](https://datascientest.com/prometheus-tout-savoir#:~:text=Parmi%20les%20nombreuses%20technologies%20disponibles%2C,dans%20la%20communaut%C3%A9%20des%20d%C3%A9veloppeurs)). Pour une surveillance réseau centralisée, Prometheus excelle par son modèle de collecte (*pull*) et la richesse de son langage de requête (PromQL), qui permettent de suivre l’ensemble de vos systèmes et d’identifier rapidement les problèmes de performance.

 ([Network Interface Stats | Grafana Labs
](https://grafana.com/grafana/dashboards/10488-network-interface-stats/)) *Exemple de tableau de bord Grafana affichant les métriques réseau d’interfaces (débit cumulé et instantané par interface). Prometheus collecte ces données via des *exporters* (par ex. Node Exporter ou SNMP) et Grafana les visualise. De tels tableaux de bord aident à repérer les interfaces saturées, les volumes de trafic anormaux ou les erreurs, sur l’ensemble de vos serveurs.* 

### Installation et configuration de Prometheus (avec Node Exporter)

1. **Installation de Prometheus** : Téléchargez la dernière version stable depuis le site officiel (ou installez-le via votre gestionnaire de paquets s’il est disponible). Pour une installation manuelle, obtenez l’archive tar.gz de Prometheus, puis extrayez-la : par exemple, sous Linux, utilisez `wget` pour récupérer le fichier puis `tar xvfz prometheus-<version>.linux-amd64.tar.gz` pour l’extraire. Placez les binaires (prometheus et promtool) dans un répertoire approprié (ex. `/usr/local/bin`) ou exécutez-les depuis le dossier extrait ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=wget%20https%3A%2F%2Fgithub.com%2Fprometheus%2Fprometheus%2Freleases%2Fdownload%2Fv2.53.1%2Fprom%20etheus)). Il est recommandé de créer un utilisateur dédié `prometheus` sans login pour exécuter le service ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=Terminal%20window)). *Astuce :* Prometheus peut également être déployé via Docker ou orchestré dans Kubernetes selon votre infrastructure, mais l’installation “standalone” suffit pour un début.

2. **Configuration de Prometheus** : Éditez le fichier de configuration `prometheus.yml` (fourni dans l’archive) pour définir les **cibles à surveiller**. Par défaut, Prometheus se scrute lui-même sur `localhost:9090`. Pour superviser d’autres machines, il faut utiliser des *exporters*. Le plus basique est **Node Exporter**, qui expose les métriques système (CPU, mémoire, disque **et réseau** notamment) de la machine sur laquelle il tourne ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=,le%20disque%20et%20le%20r%C3%A9seau)). Déployez Node Exporter sur chaque serveur à superviser (binaire téléchargeable sur le GitHub Prometheus, à lancer sur le port par défaut 9100). Ensuite, dans `prometheus.yml`, ajoutez un job de scrape : par ex. : 

   ```yaml
   scrape_configs:
     - job_name: 'node_exporter'
       static_configs:
         - targets: ['<IP_ou_nom>:9100']
   ``` 

   pour chaque cible à surveiller ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=,Node%20Exporter)). Vous pouvez ajouter plusieurs IP/serveurs sous `targets`. Ajustez également `scrape_interval` (15s par défaut) si vous souhaitez une fréquence de collecte différente ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=global%3A)).  

3. **Démarrage du service** : Lancez Prometheus en utilisant la configuration. Si installé manuellement, exécutez `./prometheus --config.file=prometheus.yml` depuis le dossier adéquat. Si vous avez installé via un package ou que vous souhaitez l’intégrer au démarrage système, créez un service systemd (voir l’exemple dans la doc Prometheus) ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=service%20,de%20service%20pour%20Prometheus)) ([Prometheus | DevSecOps](https://blog.stephane-robert.info/docs/observer/metriques/prometheus/#:~:text=User%3Dprometheus)). Une fois démarré, accédez à l’interface web de Prometheus via `http://<serveur>:9090`. Dans l’onglet *Status > Targets*, vous devriez voir vos cibles (node exporters) apparaître comme **UP** si tout va bien. 

4. **Utilisation pour le monitoring réseau** : Dès que Prometheus collecte les métriques de vos serveurs, vous pouvez requêter celles-ci pour surveiller le réseau. Par exemple, les compteurs `node_network_receive_bytes_total` et `node_network_transmit_bytes_total` (exposés par Node Exporter) donnent le total de bytes reçus/émis par interface. En utilisant PromQL, on peut calculer le débit en bytes/s sur 5 minutes par interface : 

   ```
   rate(node_network_receive_bytes_total{device="eth0"}[5m])
   ``` 

   qui renvoie le taux de réception sur *eth0*. Vous pouvez créer des tableaux de bord dans Grafana pour tracer ces valeurs dans le temps (Prometheus peut servir de source de données Grafana). Par exemple, le graphique ci-dessus illustre le trafic entrant/sortant cumulé sur deux interfaces et le débit instantané, ce qui permet de voir l’évolution de la bande passante utilisée sur chaque lien. De plus, Prometheus conserve l’historique des métriques (par défaut en mémoire locale, configurable en durée de rétention), ce qui vous permet d’analyser les tendances (pics quotidiens de trafic, croissance du volume, etc.) et d’**anticiper les besoins**. 

5. **Alertes et suivi centralisé** : Prometheus peut également déclencher des alertes via Alertmanager si certains seuils sont dépassés. Par exemple, vous pourriez définir une alerte si le taux d’erreur d’une interface (`node_network_receive_errs_total`) augmente ou si le trafic sortant dépasse un certain Mb/s sur une longue durée (signe possible d’une saturation ou d’une fuite de données). En centralisant ces métriques de tous vos serveurs, Prometheus vous offre **une visibilité complète sur votre infrastructure réseau** et vous évite de devoir vous connecter à chaque machine pour vérifier manuellement – un tableau de bord ou une requête PromQL agrégée peut montrer en un coup d’œil l’état de l’ensemble (par ex., l’interface la plus occupée du parc, ou le total de trafic agrégé).  

En résumé, **Prometheus + Node Exporter** fournissent une solution robuste pour la supervision continue des performances réseau. Après avoir diagnostiqué et optimisé localement avec les outils Linux (ping, iftop, etc.), l’intégration de Prometheus dans votre environnement vous permet de **pérenniser le monitoring**, d’automatiser la détection des anomalies et d’obtenir des **données historiques** pour appuyer vos décisions (ajout de bande passante, refonte du réseau, équilibrage de charge...). Une supervision centralisée et proactive vous assure que la configuration réseau reste optimale dans le temps et que tout regain de latence ou baisse de débit sera détecté et corrigé rapidement. 

